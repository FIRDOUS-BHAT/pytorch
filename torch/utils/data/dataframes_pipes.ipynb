{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3610jvsc74a57bd0eb5e09632d6ea1cbf3eb9da7e37b7cf581db5ed13074b21cc44e159dc62acdab",
   "display_name": "Python 3.6.10 64-bit ('dataloader': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## How DataFrames (DF) and DataPipes (DP) can work together"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import torch\n",
    "reload(torch)\n",
    "from torch.utils.data import IterDataPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example IterDataPipe\n",
    "class ExampleIterPipe(IterDataPipe):\n",
    "    def __init__(self, range = 20):\n",
    "        self.range = range\n",
    "    def __iter__(self):\n",
    "        for i in range(self.range):\n",
    "            yield i\n",
    "\n",
    "def get_dataframes_pipe(range = 10, dataframe_size = 7):\n",
    "    return ExampleIterPipe(range = range).map(lambda i: (i, i % 3)).to_dataframes_pipe(columns = ['i','j'], dataframe_size = dataframe_size)\n",
    "\n",
    "def get_regular_pipe(range = 10):\n",
    "    return ExampleIterPipe(range = range).map(lambda i: (i, i % 3))\n"
   ]
  },
  {
   "source": [
    "Doesn't matter how DF composed internally, iterator over DF Pipe gives single rows to user. This is similar to regular DataPipe."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DataFrames Pipe\n   i  j\n0  0  0\n   i  j\n1  1  1\n   i  j\n2  2  2\n   i  j\n3  3  0\n   i  j\n4  4  1\n   i  j\n5  5  2\n   i  j\n6  6  0\n   i  j\n0  7  1\n   i  j\n1  8  2\n   i  j\n2  9  0\nRegular DataPipe\n(0, 0)\n(1, 1)\n(2, 2)\n(3, 0)\n(4, 1)\n(5, 2)\n(6, 0)\n(7, 1)\n(8, 2)\n(9, 0)\n"
     ]
    }
   ],
   "source": [
    "print('DataFrames Pipe')\n",
    "dp = get_dataframes_pipe()\n",
    "for i in dp:\n",
    "    print(i)\n",
    "\n",
    "print('Regular DataPipe')\n",
    "dp = get_regular_pipe()\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "You can iterate over raw DF using `raw_iterator`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   i  j\n0  0  0\n1  1  1\n2  2  2\n3  3  0\n4  4  1\n5  5  2\n6  6  0\n   i  j\n0  7  1\n1  8  2\n2  9  0\n"
     ]
    }
   ],
   "source": [
    "dp = get_dataframes_pipe()\n",
    "for i in dp.raw_iterator():\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "Operations over DF Pipe is captured"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "var_4 = input_var_3.i * 100\nvar_5 = var_4 + input_var_3.j\nvar_6 = var_5 - 2.7\ninput_var_3[\"y\"] = var_6\n"
     ]
    }
   ],
   "source": [
    "dp = get_dataframes_pipe(dataframe_size = 3)\n",
    "dp['y'] = dp.i * 100 + dp.j - 2.7\n",
    "print(dp.ops_str())\n"
   ]
  },
  {
   "source": [
    "Captured operations executed on `__next__` calls of constructed DataPipe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   i  j      y\n0  0  0   -2.7\n1  1  1   98.3\n2  2  2  199.3\n   i  j      y\n0  3  0  297.3\n1  4  1  398.3\n2  5  2  499.3\n   i  j      y\n0  6  0  597.3\n1  7  1  698.3\n2  8  2  799.3\n   i  j      y\n0  9  0  897.3\n"
     ]
    }
   ],
   "source": [
    "dp = get_dataframes_pipe(dataframe_size = 3)\n",
    "dp['y'] = dp.i * 100 + dp.j - 2.7\n",
    "for i in dp.raw_iterator():\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "`shuffle` of DataFramePipe effects rows in individual manner"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   i  j      y\n2  2  2  199.3\n0  3  0  297.3\n1  4  1  398.3\n   i  j      y\n2  5  2  499.3\n1  7  1  698.3\n2  8  2  799.3\n   i  j      y\n0  6  0  597.3\n0  0  0   -2.7\n1  1  1   98.3\n   i  j      y\n0  9  0  897.3\n(9, 0)\n(0, 0)\n(8, 2)\n(1, 1)\n(5, 2)\n(2, 2)\n(4, 1)\n(6, 0)\n(7, 1)\n(3, 0)\n"
     ]
    }
   ],
   "source": [
    "dp = get_dataframes_pipe(dataframe_size = 3)\n",
    "dp['y'] = dp.i * 100 + dp.j - 2.7\n",
    "dp = dp.shuffle()\n",
    "for i in dp.raw_iterator():\n",
    "    print(i)\n",
    "\n",
    "# this is similar to shuffle of regular DataPipe\n",
    "dp = get_regular_pipe()\n",
    "dp = dp.shuffle()\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "You can continue mixing DF and DP operations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    i   j          y\n0 -14 -17  2803000.0\n1 -13 -16  3813000.0\n0 -17 -17  -197000.0\n    i   j          y\n2  -9 -15  7823000.0\n0  -8 -17  8803000.0\n2 -12 -15  4823000.0\n    i   j          y\n0 -11 -17  5803000.0\n2 -15 -15  1823000.0\n1 -16 -16   813000.0\n    i   j          y\n1 -10 -16  6813000.0\n"
     ]
    }
   ],
   "source": [
    "dp = get_dataframes_pipe(dataframe_size = 3)\n",
    "dp['y'] = dp.i * 100 + dp.j - 2.7\n",
    "dp = dp.shuffle()\n",
    "dp = dp - 17\n",
    "dp['y'] = dp.y * 10000\n",
    "for i in dp.raw_iterator():\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "Batching combines everything into `list` it is possible to nest `list`s. List may have any number of DataFrames as soon as total number of rows equal to batch size."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[   i  j\n0  3  0\n1  4  1]\n[   i  j\n2  5  2\n0  9  0]\n[   i  j\n0  0  0\n0  6  0]\n[   i  j\n1  7  1\n2  2  2]\n[   i  j\n2  8  2\n1  1  1]\n[(1, 1), (0, 0)]\n[(6, 0), (2, 2)]\n[(5, 2), (9, 0)]\n[(4, 1), (8, 2)]\n[(3, 0), (7, 1)]\n"
     ]
    }
   ],
   "source": [
    "dp = get_dataframes_pipe(dataframe_size = 3)\n",
    "dp = dp.shuffle()\n",
    "dp = dp.batch(2)\n",
    "for i,v in enumerate(dp):\n",
    "    print(v)\n",
    "\n",
    "# this is similar to batching of regular DataPipe\n",
    "dp = get_regular_pipe()\n",
    "dp = dp.shuffle()\n",
    "dp = dp.batch(2)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "`concat` should work only of DF with same schema, this code should produce an error "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   i  j      y\n",
      "0  0  0   -2.7\n",
      "1  1  1   98.3\n",
      "2  2  2  199.3\n",
      "   i  j      y\n",
      "0  3  0  297.3\n",
      "1  4  1  398.3\n",
      "2  5  2  499.3\n",
      "   i  j\n",
      "0  0  0\n",
      "   i  j\n",
      "1  1  1\n",
      "   i  j\n",
      "2  2  2\n",
      "   i  j\n",
      "3  3  0\n",
      "   i  j\n",
      "0  4  1\n",
      "   i  j\n",
      "1  5  2\n",
      "   i  j\n",
      "2  6  0\n",
      "   i  j\n",
      "3  7  1\n"
     ]
    }
   ],
   "source": [
    "dp0 = get_dataframes_pipe(range = 8, dataframe_size = 4)\n",
    "dp = get_dataframes_pipe(range = 6, dataframe_size = 3)\n",
    "dp['y'] = dp.i * 100 + dp.j - 2.7\n",
    "dp = dp.concat(dp0)\n",
    "for i,v in enumerate(dp.raw_iterator()):\n",
    "    print(v)"
   ]
  },
  {
   "source": [
    "`unbatch` of `list` with DataFrame works similarly to regular unbatch.\n",
    "Note: DataFrame sizes might change"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   i  j      y      z\n0  0  0   -2.7 -102.7\n1  1  1   98.3   -1.7\n2  2  2  199.3   99.3\n0  3  0  297.3  197.3\n1  4  1  398.3  298.3\n   i  j      y      z\n2  5  2  499.3  399.3\n0  6  0  597.3  497.3\n1  7  1  698.3  598.3\n2  8  2  799.3  699.3\n0  9  0  897.3  797.3\n    i  j       y       z\n1  10  1   998.3   898.3\n2  11  2  1099.3   999.3\n0  12  0  1197.3  1097.3\n1  13  1  1298.3  1198.3\n2  14  2  1399.3  1299.3\n    i  j       y       z\n0  15  0  1497.3  1397.3\n1  16  1  1598.3  1498.3\n2  17  2  1699.3  1599.3\n"
     ]
    }
   ],
   "source": [
    "dp = get_dataframes_pipe(range = 18, dataframe_size = 3)\n",
    "dp['y'] = dp.i * 100 + dp.j - 2.7\n",
    "dp = dp.batch(5).batch(3).batch(1).unbatch(unbatch_level = 3)\n",
    "\n",
    "# Here is bug with unbatching which doesn't detect DF type.\n",
    "dp['z'] = dp.y - 100\n",
    "\n",
    "for i in dp.raw_iterator():\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "`map` applied to individual rows, `nesting_level` argument used to penetrate batching"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[       i      j\n0  1.111  1.111\n1  1.112  1.112\n2  1.113  1.113\n0  1.114  1.111\n1  1.115  1.112]\n[       i      j\n2  1.116  1.113\n0  1.117  1.111\n1  1.118  1.112\n2  1.119  1.113\n0  1.120  1.111]\n[(1.111, 0), (1.112, 1), (1.113, 2), (1.114, 0), (1.115, 1)]\n[(1.116, 2), (1.117, 0), (1.118, 1), (1.119, 2), (1.12, 0)]\n"
     ]
    }
   ],
   "source": [
    "dp = get_dataframes_pipe(range = 10, dataframe_size = 3)\n",
    "dp = dp.map(lambda x: x + 1111)\n",
    "dp = dp.batch(5).map(lambda x: x / 1000, nesting_level = 1)\n",
    "\n",
    "for i in dp:\n",
    "    print(i)\n",
    "\n",
    "# Similarly works on row level for classic DataPipe elements\n",
    "dp = get_regular_pipe(range = 10)\n",
    "dp = dp.map(lambda x: (x[0] + 1111, x[1]))\n",
    "dp = dp.batch(5).map(lambda x: (x[0] / 1000, x[1]), nesting_level = 1)\n",
    "\n",
    "for i in dp:\n",
    "    print(i)\n",
    "\n"
   ]
  },
  {
   "source": [
    "`filter` applied to individual rows, `nesting_level` argument used to penetrate batching"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[    i  j\n0   6  0\n1   7  1\n2   8  2\n0   9  0\n1  10  1]\n[    i  j\n2  11  2\n0  12  0]\n[(6, 0), (7, 1), (8, 2), (9, 0), (10, 1)]\n[(11, 2), (12, 0)]\n"
     ]
    }
   ],
   "source": [
    "dp = get_dataframes_pipe(range = 30, dataframe_size = 3)\n",
    "dp = dp.filter(lambda x: x.i > 5)\n",
    "dp = dp.batch(5).filter(lambda x: x.i < 13, nesting_level = 1)\n",
    "\n",
    "for i in dp:\n",
    "    print(i)\n",
    "\n",
    "# Similarly works on row level for classic DataPipe elements\n",
    "dp = get_regular_pipe(range = 30)\n",
    "dp = dp.filter(lambda x: x[0] > 5)\n",
    "dp = dp.batch(5).filter(lambda x: x[0] < 13, nesting_level = 1)\n",
    "\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  }
 ]
}